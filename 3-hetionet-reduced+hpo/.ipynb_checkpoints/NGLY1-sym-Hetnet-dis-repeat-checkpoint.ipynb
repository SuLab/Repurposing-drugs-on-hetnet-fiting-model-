{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchor NGLY1 symptoms into hetnet (through DIS-SYM edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NGLY1 symptoms links to diseases in hetnet can be found:\n",
    "- data integration with the most current (curated/text mining) datasets (current knowledge structured in DBs)\n",
    "- text/data mining the literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIS-SYM datasets\n",
    "- Barabasi (HSDN)\n",
    "- Orphanet\n",
    "- HPO project\n",
    "- Rob Hoehndorf\n",
    "- Tudor Groza\n",
    "- Monarch (not yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib_venn import venn2, venn2_unweighted, venn3, venn3_unweighted\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data path\n",
    "path = '/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/ngly1/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGLY1 SYMPTOMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesh_code</th>\n",
       "      <th>mesh_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MESH:D009123</td>\n",
       "      <td>Muscle Hypotonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MESH:C562827</td>\n",
       "      <td>Alacrima</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mesh_code         mesh_term\n",
       "0  MESH:D009123  Muscle Hypotonia\n",
       "1  MESH:C562827          Alacrima"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load manually curated mesh symptoms\n",
    "ngly1_sym_mesh_df = pd.read_table('{}manual-curation/ngly1-mesh.tsv'.format(path), header=None)\n",
    "ngly1_sym_mesh_df.columns = ['mesh_code', 'mesh_term']\n",
    "ngly1_sym_mesh_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGLY1 deficiency symptoms (MESH): 15\n"
     ]
    }
   ],
   "source": [
    "# Number of terms mapped to mesh\n",
    "ngly1_sym_mesh_list = ngly1_sym_mesh_df.mesh_code.unique()\n",
    "print('NGLY1 deficiency symptoms (MESH): {}'.format(len(ngly1_sym_mesh_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hp_code</th>\n",
       "      <th>hp_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP:0001263</td>\n",
       "      <td>Global developmental delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP:0001252</td>\n",
       "      <td>Muscular hypotonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hp_code                     hp_term\n",
       "0  HP:0001263  Global developmental delay\n",
       "1  HP:0001252          Muscular hypotonia"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load hp sym\n",
    "ngly1_sym_hp_df = pd.read_table('{}manual-curation/ngly1-hp.tsv'.format(path), header=None)\n",
    "ngly1_sym_hp_df.columns = ['hp_code', 'hp_term']\n",
    "ngly1_sym_hp_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGLY1 deficiency symptoms (HP): 28\n"
     ]
    }
   ],
   "source": [
    "# Number of terms mapped to mesh\n",
    "ngly1_sym_hp_list = ngly1_sym_hp_df.hp_code.unique()\n",
    "print('NGLY1 deficiency symptoms (HP): {}'.format(len(ngly1_sym_hp_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DISEASE-SYMPTOM EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doid_code</th>\n",
       "      <th>doid_name</th>\n",
       "      <th>mesh_id</th>\n",
       "      <th>mesh_name</th>\n",
       "      <th>cooccurrence</th>\n",
       "      <th>expected</th>\n",
       "      <th>enrichment</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>p_fisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DOID:10652</td>\n",
       "      <td>Alzheimer's disease</td>\n",
       "      <td>MESH:D004314</td>\n",
       "      <td>Down Syndrome</td>\n",
       "      <td>800</td>\n",
       "      <td>35.619601</td>\n",
       "      <td>22.459544</td>\n",
       "      <td>39.918352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DOID:10652</td>\n",
       "      <td>Alzheimer's disease</td>\n",
       "      <td>MESH:D008569</td>\n",
       "      <td>Memory Disorders</td>\n",
       "      <td>1593</td>\n",
       "      <td>76.580532</td>\n",
       "      <td>20.801631</td>\n",
       "      <td>41.885877</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doid_code            doid_name       mesh_id         mesh_name  \\\n",
       "0  DOID:10652  Alzheimer's disease  MESH:D004314     Down Syndrome   \n",
       "1  DOID:10652  Alzheimer's disease  MESH:D008569  Memory Disorders   \n",
       "\n",
       "   cooccurrence   expected  enrichment  odds_ratio  p_fisher  \n",
       "0           800  35.619601   22.459544   39.918352       0.0  \n",
       "1          1593  76.580532   20.801631   41.885877       0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hetnet v1.0\n",
    "# source: Symptom edges from hetionet v1.0 [https://github.com/dhimmel/integrate/blob/master/integrate.ipynb]\n",
    "commit = '60d611892bf387b5b23c5f2e2e3bc472cfce85f3'\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/medline/' + commit + '/data/disease-symptom-cooccurrence.tsv'\n",
    "hetionet_df = pd.read_table(url)\n",
    "hetionet_df.head(2)\n",
    "hetionet_df['mesh_id'] = 'MESH:' + hetionet_df['mesh_id'].astype(str)\n",
    "hetionet_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>symptom_term</th>\n",
       "      <th>disease_term</th>\n",
       "      <th>cooccurs</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>disease_meshid</th>\n",
       "      <th>symptom_meshid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aging, Premature</td>\n",
       "      <td>Respiratory Syncytial Virus Infections</td>\n",
       "      <td>1</td>\n",
       "      <td>3.464551</td>\n",
       "      <td>MESH:D018357</td>\n",
       "      <td>MESH:D019588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aging, Premature</td>\n",
       "      <td>Orthomyxoviridae Infections</td>\n",
       "      <td>1</td>\n",
       "      <td>3.464551</td>\n",
       "      <td>MESH:D009976</td>\n",
       "      <td>MESH:D019588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      symptom_term                            disease_term  \\\n",
       "0           0  Aging, Premature  Respiratory Syncytial Virus Infections   \n",
       "1           1  Aging, Premature             Orthomyxoviridae Infections   \n",
       "\n",
       "   cooccurs  tfidf_score disease_meshid symptom_meshid  \n",
       "0         1     3.464551   MESH:D018357   MESH:D019588  \n",
       "1         1     3.464551   MESH:D009976   MESH:D019588  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HSDN - Barabasi 2014\n",
    "# source: https://github.com/LABrueggs/HSDN\n",
    "# The supplementary data released by Zhou et al. (HSDN - barabasi) identifies diseases and symptoms \n",
    "# by their MeSH names, but does not include the associated MeSH IDs. \n",
    "# To ease interoperability we have performed the minor task of appending the relevant MeSH IDs to these files. \n",
    "# read HSDN supplement that was mapped to MESH\n",
    "url = 'https://raw.githubusercontent.com/LABrueggs/HSDN/master/Combined-Output.tsv'\n",
    "hsdn_df = pd.read_table(url)\n",
    "hsdn_df = hsdn_df.rename(columns={\n",
    "    'MeSH Symptom Term' : 'symptom_term',\n",
    "    'MeSH Disease Term' : 'disease_term',\n",
    "    'PubMed occurrence' : 'cooccurs', \n",
    "    'TFIDF score' : 'tfidf_score',\n",
    "    'MeSH Disease ID' : 'disease_meshid',\n",
    "    'MeSH Symptom ID' : 'symptom_meshid'\n",
    "                    })\n",
    "hsdn_df.head(2)\n",
    "hsdn_df['disease_meshid'] = 'MESH:' + hsdn_df['disease_meshid'].astype(str)\n",
    "hsdn_df['symptom_meshid'] = 'MESH:' + hsdn_df['symptom_meshid'].astype(str)\n",
    "hsdn_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data/orphanet-disease-symptom.tsv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f46b79ca6db5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Provenance: /home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data/orphanet-data-provenance.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Parser: /home/nuria/workspace/utils3/hetionet/orphanet.py::orphadata_xml_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0morphanet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data/orphanet-disease-symptom.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0morphanet_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data/orphanet-disease-symptom.tsv' does not exist"
     ]
    }
   ],
   "source": [
    "# Orphanet 2016\n",
    "# Source url: http://www.orphadata.org/cgi-bin/inc/product4.inc.php\n",
    "# Source file: /home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/en_product4_HPO.xml\n",
    "# Provenance: /home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/orphanet-data-provenance.txt\n",
    "# Parser: /home/nuria/workspace/utils3/hetionet/orphanet.py::orphadata_xml_parser\n",
    "orphanet_df = pd.read_table('/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/orphanet-disease-symptom.tsv')\n",
    "orphanet_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO phenotype annotation 2017 (not used in this analysis: 2017 HPO update and diseases not DO normalized)\n",
    "# Source: http://compbio.charite.de/jenkins/job/hpo.annotations/lastStableBuild/artifact/misc/phenotype_annotation.tab\n",
    "# Provenance: 2017-01-23 20:45\n",
    "hpo17_df = pd.read_table('http://compbio.charite.de/jenkins/job/hpo.annotations/lastStableBuild/artifact/misc/phenotype_annotation.tab')\n",
    "hpo17_df.head(2)\n",
    "hpo17_df.columns = ['db', 'disease_id', 'db_term', 'qualifier', 'hp_id', 'db_ref', 'evidence', 'onset', 'frequency', 'with', 'aspect', 'synonym', 'date', 'assigned_by' ]\n",
    "hpo17_df.head(2)\n",
    "hpo17_df['disease_id'] = hpo17_df['db'] + ':' + hpo17_df['disease_id'].astype(str)\n",
    "hpo17_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO phenotype annotation 2016 NORMALIZED (2016 HPO and DO normalized)\n",
    "# Source: IBI Lab\n",
    "# Provenance: 2016-01-13 13:18\n",
    "# Read DisPhe associations (DO/HP) ID normalized, obsolete included\n",
    "data = '/home/nuria/IbiLab/MedBioinformatics/trait-based-diseasome-2015/data/out/hpCuratedDP-refined.tab'\n",
    "hpo_df = pd.read_table(data, sep='\\t', names=['do_id','hp_id'])\n",
    "hpo_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Robert Hoehndorf 2015\n",
    "# Source: http://aber-owl.net/aber-owl/diseasephenotypes/\n",
    "# Paper: https://www.ncbi.nlm.nih.gov/pubmed/26051359\n",
    "#url = 'http://aber-owl.net/aber-owl/diseasephenotypes/data/disease_phenotypes.doa'\n",
    "#rh_df = pd.read_table(url, sep='\\t', names=['DB', 'do_id', 'Object_Symbol', 'Qualifier_score', 'hp_id', 'Reference', 'Evidence_Code', 'empty', 'Aspect', 'DB_Object_Name', 'DB_Object_Synonym', 'DB_Object_Type', 'Taxon', 'Date', 'Assigned_By', 'Annotation_Extension', 'Gene_Product_Form_ID'])\n",
    "#rh_df.drop(rh_df.index[[0]], inplace=True)\n",
    "#rh_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Robert Hoehndorf 2015 NORMALIZED\n",
    "# Source: http://aber-owl.net/aber-owl/diseasephenotypes/\n",
    "# Paper: https://www.ncbi.nlm.nih.gov/pubmed/26051359\n",
    "#url = '/home/nuria/IbiLab/MedBioinformatics/trait-based-diseasome-2015/data/out/disease_phenotypes_doid_hpid_refined.doa'\n",
    "#rh_df = pd.read_table(url, sep='\\t', names=['DB', 'do_id', 'Object_Symbol', 'Qualifier_score', 'hp_id', 'Reference', 'Evidence_Code', 'empty', 'Aspect', 'DB_Object_Name', 'DB_Object_Synonym', 'DB_Object_Type', 'Taxon', 'Date', 'Assigned_By', 'Annotation_Extension', 'Gene_Product_Form_ID'])\n",
    "#rh_df.drop(rh_df.index[[0]], inplace=True)\n",
    "# Read DisPhe associations (DO/HP) ID normalized, obsolete included, without MP phenotypes\n",
    "data = '/home/nuria/IbiLab/MedBioinformatics/trait-based-diseasome-2015/data/out/aberOwlTMDPWithoutMP-refined.tab'\n",
    "rh_df = pd.read_table(data, sep='\\t', names=['do_id','hp_id'])\n",
    "rh_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tudor Groza 2015 \n",
    "# Source: Not accessible at http://pubmed-browser.human-phenotype-ontology.org/ \n",
    "# Paper: https://www.ncbi.nlm.nih.gov/pubmed/26119816\n",
    "# Tudor Groza 2015 NORMALIZED <= Source: IBI Lab\n",
    "# Read DisPhe associations (DO/HP) ID normalized, obsolete included\n",
    "data = '/home/nuria/IbiLab/MedBioinformatics/trait-based-diseasome-2015/data/out/hpTMDP-refined.tab'\n",
    "tg_df = pd.read_table(data, sep='\\t', names=['do_id','hp_id'])\n",
    "tg_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYMPTOMS OVERLAPS: NGLY1 - hetnet - datasets\n",
    "What dataset covers more ngly1 sym? \n",
    "- Text mining datasets (8/15 symptoms (MESH)) [HPO mappings]\n",
    "- AberOWL dataset (10/15); HPO-Curated (9/15) (MESH) [HPO+UMLS inferred mappings]\n",
    "- AberOWL dataset (27/28); HPO-Curated (26/28) (HPO) [HPO mappings] also [HPO+UMLS inferred mappings]\n",
    "\n",
    "Coverage of NGLY1 symptoms with data integration:\n",
    "- 10/15 (MESH) [HPO mappings]\n",
    "- 12/15; (5<=hetnet, 7<=other) (MESH) [HPO+UMLS inferred mappings]\n",
    "- 27/28 (5<=hetnet, 22<=other) (HPO) [HPO mappings] also [HPO+UMLS inferred mappings]\n",
    "\n",
    "##### Conclusion: Using HPO 2016 + UMLS 2016 inferred mappings we increase NGLY1 symptom recall  (above all from HPO text mined terms)\n",
    "##### Note: List of hetnet sym comes from the dis-sym edge dataset in the integrated network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load mesh symptoms\n",
    "# hetnet: from Dis-Sym edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## validation of mesh symptoms list\n",
    "## Inconsistent: 438 SYM nodes in hetionet (from MESH classification branch) - 426 SYM with link to disease\n",
    "# source: Symptoms nodes from hetionet v1.0 [https://github.com/dhimmel/integrate/blob/master/integrate.ipynb]\n",
    "commit = 'a7036a37302973b15ab949aab4056d9bc062910e'\n",
    "#url = rawgit('dhimmel', 'mesh', commit, 'data/symptoms.tsv')\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/mesh/' + commit + '/data/symptoms.tsv'\n",
    "symptom_df1 = pd.read_table(url)\n",
    "symptom_df1.head(2)\n",
    "#len(symptom_df1.mesh_id.unique()) # 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: input of mesh symptoms in nb disease-symptom data mining \n",
    "# [https://nbviewer.ipython.org/github/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/symptoms.ipynb]\n",
    "url = url = 'https://raw.githubusercontent.com/dhimmel/mesh/e561301360e6de2140dedeaa7c7e17ce4714eb7f/data/symptoms.tsv'\n",
    "symptom_df2 = pd.read_table(url)\n",
    "symptom_df2.head(2)\n",
    "#len(symptom_df2.mesh_id.unique()) # 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mesh symptoms are in the mesh repo\n",
    "# source: github/dhimmel, mesh repo, data folder (no commit appears)\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/mesh/gh-pages/data/symptoms.tsv'\n",
    "symptom_df3 = pd.read_table(url)\n",
    "symptom_df3.head(2)\n",
    "#len(symptom_df3.mesh_id.unique()) # 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downloaded file from mesh repo in the daniel's github, i think..\n",
    "symptom_df4 = pd.read_table(\"data/hetionet-symptoms.tsv\")\n",
    "symptom_df4.head(2)\n",
    "#len(symptom_df4.mesh_id.unique()) # 438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: output disease-symptoms cooccurrences in nb disease-symptom data mining \n",
    "# [https://nbviewer.ipython.org/github/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/symptoms.ipynb]\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/medline/gh-pages/data/disease-symptom-cooccurrence.tsv'\n",
    "symptom_df5 = pd.read_table(url)\n",
    "symptom_df5.head(2)\n",
    "#len(symptom_df5.mesh_id.unique()) # 426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: Symptom edges from hetionet v1.0 [https://github.com/dhimmel/integrate/blob/master/integrate.ipynb]\n",
    "commit = '60d611892bf387b5b23c5f2e2e3bc472cfce85f3'\n",
    "# url = rawgit('dhimmel', 'medline', commit, 'data/disease-symptom-cooccurrence.tsv')\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/medline/' + commit + '/data/disease-symptom-cooccurrence.tsv'\n",
    "symptom_df6 = pd.read_table(url)\n",
    "symptom_df6.head(2)\n",
    "#len(symptom_df6.mesh_id.unique()) # 426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rest = ( set(list(symptom_df1.mesh_id)) - set(list(symptom_df2.mesh_id)) )\n",
    "print('1-2: {}'.format(len(rest)))\n",
    "rest = ( set(list(symptom_df1.mesh_id)) - set(list(symptom_df3.mesh_id)) )\n",
    "print('1-3: {}'.format(len(rest)))\n",
    "rest = ( set(list(symptom_df1.mesh_id)) - set(list(symptom_df6.mesh_id)) )\n",
    "print('1-6: {}'.format(len(rest)))\n",
    "print('1-6: {}'.format(rest))\n",
    "rest = list(rest)\n",
    "rest_d = {'mesh_id' : rest}\n",
    "rest_df = pd.DataFrame.from_dict(data=rest_d)\n",
    "rest_df = pd.merge(rest_df,symptom_df1, on='mesh_id')\n",
    "print('These are the 12 symptom nodes without edges:')\n",
    "rest_df\n",
    "# Conclusion: Symptom nodes (438) in hetionet, symptom nodes involved in disease-symptom edges (426). \n",
    "## end of validation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: the ngly1 sym 'hyperlactemia' is in hetionet but without a link to a disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coverage ngly1 - hetionet - Other datasets\n",
    "# Load HP2MESH mappings from HP ontology\n",
    "hpo_mappings = pd.read_table(\"/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/hp-hp2mesh-mappings.tsv\".format(path))\n",
    "hpo_mappings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mappings\n",
    "orphanet_mesh_df = pd.merge(orphanet_df,hpo_mappings, on='hp_code')\n",
    "hpo_mesh_df = pd.merge(hpo_df,hpo_mappings, left_on='hp_id', right_on='hp_code')\n",
    "rh_mesh_df = pd.merge(rh_df,hpo_mappings, left_on='hp_id', right_on='hp_code')\n",
    "tg_mesh_df = pd.merge(tg_df,hpo_mappings, left_on='hp_id', right_on='hp_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mesh symptoms\n",
    "# Number of NGLY1 terms mapped to mesh\n",
    "ngly1_sym_mesh_list = ngly1_sym_mesh_df.mesh_code.unique()\n",
    "print('NGLY1 deficiency symptoms (MESH): {}'.format(len(ngly1_sym_mesh_list)))\n",
    "# Number of hetionet symptom terms \n",
    "hetionet_sym_mesh_list = hetionet_df.mesh_id.unique()\n",
    "print('Hetionet symptoms (MESH): {}'.format(len(hetionet_sym_mesh_list)))\n",
    "# Number of hsdn - barabasi symptom terms\n",
    "hsdn_sym_mesh_list = hsdn_df.symptom_meshid.unique()\n",
    "print('HSDN symptoms (MESH): {}'.format(len(hsdn_sym_mesh_list)))\n",
    "# Number of orphanet symptom terms\n",
    "orpha_sym_mesh_list = orphanet_mesh_df.mesh_code.unique()\n",
    "print('Orphanet symptoms (MESH): {}'.format(len(orpha_sym_mesh_list)))\n",
    "# Number of HPO Curated symptom terms\n",
    "hpo_sym_mesh_list = hpo_mesh_df.mesh_code.unique()\n",
    "print('HPO Curated symptoms (MESH): {}'.format(len(hpo_sym_mesh_list)))\n",
    "# Number of HPO Text mining symptom terms\n",
    "tg_sym_mesh_list = tg_mesh_df.mesh_code.unique()\n",
    "print('HPO Text mining symptoms (MESH): {}'.format(len(tg_sym_mesh_list)))\n",
    "# Number of AberOWL symptom terms\n",
    "rh_sym_mesh_list = rh_mesh_df.mesh_code.unique()\n",
    "print('AberOWL symptoms (MESH): {}'.format(len(rh_sym_mesh_list)))\n",
    "# Coverage HSDN\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hsdn = set(hsdn_sym_mesh_list)\n",
    "#venn3_unweighted([ngly1,hetionet,hsdn],('NGLY1', 'Hetionet', 'HSDN'))\n",
    "#plt.show()\n",
    "venn3([ngly1,hetionet,hsdn],('NGLY1', 'Hetionet', 'HSDN'))\n",
    "plt.show()\n",
    "# Coverage Orphanet\n",
    "orphanet = set(orpha_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,orphanet],('NGLY1', 'Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "# Coverage HPO Phenotype Annotation 2016\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hpo = set(hpo_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,hpo],('NGLY1', 'Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Coverage HPO Text Mining 2015 (TGroza)\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hpotm = set(tg_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,hpotm],('NGLY1', 'Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "# Coverage AberOWL 2015 (RHoehndorf)\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "aberowl = set(rh_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,aberowl],('NGLY1', 'Hetionet', 'AberOWL'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conclusion: All five datasets have NGLY1 symptoms.\n",
    "# Overlap between sources\n",
    "# Curated\n",
    "venn3([ngly1,orphanet,hpo], ('NGLY1', 'Orphanet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Text mined \n",
    "venn3([ngly1,aberowl,hpotm], ('NGLY1', 'AberOWL', 'HPO-TextMining'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data integration: How many NGLY1 symptoms we will recover\n",
    "intersection_mesh = (ngly1 & (hsdn | orphanet | hpo | aberowl | hpotm))\n",
    "not_mapped_mesh = (ngly1 - intersection_mesh)\n",
    "print('Number of NGLY1 symptoms (MESH) uncovered with data integration: {}/{}'.format(len(intersection_mesh),len(ngly1_sym_mesh_list)))\n",
    "print('Number of NGLY1 symptoms (MESH) not covered with data integration: {}/{}'.format(len(not_mapped_mesh),len(ngly1_sym_mesh_list)))\n",
    "print('NGLY1 symptoms (MESH) not covered with data integration:')\n",
    "not_mapped_dict = {'mesh_code' : list(not_mapped_mesh)}\n",
    "not_mapped_mesh_df = pd.DataFrame.from_dict(data=not_mapped_dict)\n",
    "not_mapped_terms_df = pd.merge(not_mapped_mesh_df,ngly1_sym_mesh_df, on='mesh_code')\n",
    "not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: ALACRIMA not recovered!!! BUT, it is in DO-HPO datasets. Problem -HPO 2016- lacks some HPO-MESH xrefs \n",
    "# that are inferred using UMLS. Extract NGLY1 MESH symptoms without HPO and contact HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLGY symptoms potentially anchor by data integration\n",
    "mapped_dict = {'mesh_code' : list(intersection_mesh)}\n",
    "mapped_mesh_df = pd.DataFrame.from_dict(data=mapped_dict)\n",
    "mapped_terms_df = pd.merge(mapped_mesh_df,ngly1_sym_mesh_df, on='mesh_code')\n",
    "print('NGLY1 symptoms (MESH) covered with data integration:')\n",
    "mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check 5 MESH sym in hetnet\n",
    "ngly1_hetnet = (ngly1 & hetionet)\n",
    "print('NGLY1 symptoms (MESH) in hetnet: {}'.format(ngly1_hetnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HPO + UMLS inferred mappings\n",
    "Use these mappings to recall important symptoms in MESH as ALACRIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add mappings inferred through UMLS\n",
    "# load hp2mesh inferred mappings from UMLS\n",
    "umls_mappings = pd.read_table(\"/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/umls2016aa-hp2mesh-mappings.tsv\".format(path))\n",
    "umls_mappings['mesh_code'] = 'MESH:' + umls_mappings['mesh_code'].astype(str)\n",
    "umls_mappings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate hpo and umls hp2mesh mappings\n",
    "hpo_mappings.head(2)\n",
    "merge_df = pd.merge(hpo_mappings,umls_mappings, how='outer', on=['hp_code', 'mesh_code'])\n",
    "concat_df = pd.concat([hpo_mappings,umls_mappings]).groupby(['hp_code', 'mesh_code'])\n",
    "merge_df.shape #(1454, 5)\n",
    "len(concat_df) # 1454, the same result but the type of object is different\n",
    "type(concat_df)\n",
    "# merge is cleaner with full outer join (union of keys from both appended dataframes)\n",
    "hpo_umls_mappings = pd.merge(hpo_mappings,umls_mappings, how='outer', on=['hp_code', 'mesh_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mappings\n",
    "orphanet_mesh_df = pd.merge(orphanet_df,hpo_umls_mappings, on='hp_code')\n",
    "hpo_mesh_df = pd.merge(hpo_df,hpo_umls_mappings, left_on='hp_id', right_on='hp_code')\n",
    "rh_mesh_df = pd.merge(rh_df,hpo_umls_mappings, left_on='hp_id', right_on='hp_code')\n",
    "tg_mesh_df = pd.merge(tg_df,hpo_umls_mappings, left_on='hp_id', right_on='hp_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mesh symptoms\n",
    "# Number of NGLY1 terms mapped to mesh\n",
    "ngly1_sym_mesh_list = ngly1_sym_mesh_df.mesh_code.unique()\n",
    "print('NGLY1 deficiency symptoms (MESH): {}'.format(len(ngly1_sym_mesh_list)))\n",
    "# Number of hetionet symptom terms \n",
    "hetionet_sym_mesh_list = hetionet_df.mesh_id.unique()\n",
    "print('Hetionet symptoms (MESH): {}'.format(len(hetionet_sym_mesh_list)))\n",
    "# Number of hsdn - barabasi symptom terms\n",
    "hsdn_sym_mesh_list = hsdn_df.symptom_meshid.unique()\n",
    "print('HSDN symptoms (MESH): {}'.format(len(hsdn_sym_mesh_list)))\n",
    "# Number of orphanet symptom terms\n",
    "orpha_sym_mesh_list = orphanet_mesh_df.mesh_code.unique()\n",
    "print('Orphanet symptoms (MESH): {}'.format(len(orpha_sym_mesh_list)))\n",
    "# Number of HPO Curated symptom terms\n",
    "hpo_sym_mesh_list = hpo_mesh_df.mesh_code.unique()\n",
    "print('HPO Curated symptoms (MESH): {}'.format(len(hpo_sym_mesh_list)))\n",
    "# Number of HPO Text mining symptom terms\n",
    "tg_sym_mesh_list = tg_mesh_df.mesh_code.unique()\n",
    "print('HPO Text mining symptoms (MESH): {}'.format(len(tg_sym_mesh_list)))\n",
    "# Number of AberOWL symptom terms\n",
    "rh_sym_mesh_list = rh_mesh_df.mesh_code.unique()\n",
    "print('AberOWL symptoms (MESH): {}'.format(len(rh_sym_mesh_list)))\n",
    "# Coverage HSDN\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hsdn = set(hsdn_sym_mesh_list)\n",
    "#venn3_unweighted([ngly1,hetionet,hsdn],('NGLY1', 'Hetionet', 'HSDN'))\n",
    "#plt.show()\n",
    "venn3([ngly1,hetionet,hsdn],('NGLY1', 'Hetionet', 'HSDN'))\n",
    "plt.show()\n",
    "# Coverage Orphanet\n",
    "orphanet = set(orpha_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,orphanet],('NGLY1', 'Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "# Coverage HPO Phenotype Annotation 2016\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hpo = set(hpo_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,hpo],('NGLY1', 'Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Coverage HPO Text Mining 2015 (TGroza)\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "hpotm = set(tg_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,hpotm],('NGLY1', 'Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "# Coverage AberOWL 2015 (RHoehndorf)\n",
    "ngly1 = set(ngly1_sym_mesh_list)\n",
    "hetionet = set(hetionet_sym_mesh_list)\n",
    "aberowl = set(rh_sym_mesh_list)\n",
    "venn3([ngly1,hetionet,aberowl],('NGLY1', 'Hetionet', 'AberOWL'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conclusion: All five datasets have NGLY1 symptoms. \n",
    "# Overlap between sources\n",
    "# Curated\n",
    "venn3([ngly1,orphanet,hpo], ('NGLY1', 'Orphanet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Text mined \n",
    "venn3([ngly1,aberowl,hpotm], ('NGLY1', 'AberOWL', 'HPO-TextMining'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data integration: How many NGLY1 symptoms we will recover\n",
    "intersection_mesh = (ngly1 & (hsdn | orphanet | hpo | aberowl | hpotm))\n",
    "not_mapped_mesh = (ngly1 - intersection_mesh)\n",
    "print('Number of NGLY1 symptoms (MESH) uncovered with data integration: {}/{}'.format(len(intersection_mesh),len(ngly1_sym_mesh_list)))\n",
    "print('Number of NGLY1 symptoms (MESH) not covered with data integration: {}/{}'.format(len(not_mapped_mesh),len(ngly1_sym_mesh_list)))\n",
    "print('NGLY1 symptoms (MESH) not covered with data integration:')\n",
    "not_mapped_dict = {'mesh_code' : list(not_mapped_mesh)}\n",
    "not_mapped_mesh_df = pd.DataFrame.from_dict(data=not_mapped_dict)\n",
    "not_mapped_terms_df = pd.merge(not_mapped_mesh_df,ngly1_sym_mesh_df, on='mesh_code')\n",
    "ngly1_not_mapped_terms_df = not_mapped_terms_df\n",
    "not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLGY symptoms anchor by data integration\n",
    "mapped_dict = {'mesh_code' : list(intersection_mesh)}\n",
    "mapped_mesh_df = pd.DataFrame.from_dict(data=mapped_dict)\n",
    "mapped_terms_df = pd.merge(mapped_mesh_df,ngly1_sym_mesh_df, on='mesh_code')\n",
    "print('NGLY1 symptoms (MESH) covered with data integration:')\n",
    "mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conclusion: Using HPO 2016 + UMLS 2016 inferred mappings we increase NGLY1 symptom recall \n",
    "# (above all from HPO text mined terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check 5 MESH sym in hetnet\n",
    "ngly1_hetnet = (ngly1 & hetionet)\n",
    "print('NGLY1 symptoms (MESH) in hetnet: {}'.format(ngly1_hetnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coverage ngly1 - hetionet - HSDN\n",
    "# Load hp symptoms\n",
    "# Number of NGLY1 terms mapped to hp\n",
    "ngly1_sym_hp_list = ngly1_sym_hp_df.hp_code.unique()\n",
    "print('NGLY1 deficiency symptoms (HP): {}'.format(len(ngly1_sym_hp_list)))\n",
    "# Number of hetionet symptom terms \n",
    "hetionet_sym_hp_df = hetionet_df.merge(hpo_umls_mappings, left_on='mesh_id', right_on='mesh_code')\n",
    "hetionet_sym_hp_list = hetionet_sym_hp_df.hp_code.unique()\n",
    "print('Hetionet symptoms (HP): {}'.format(len(hetionet_sym_hp_list)))\n",
    "# Number of hsdn - barabasi symptom terms\n",
    "hsdn_sym_hp_df = hsdn_df.merge(hpo_umls_mappings, left_on='symptom_meshid', right_on='mesh_code')\n",
    "hsdn_sym_hp_list = hsdn_sym_hp_df.hp_code.unique()\n",
    "print('HSDN symptoms (HP): {}'.format(len(hsdn_sym_hp_list)))\n",
    "# Number of orphanet symptom terms\n",
    "orpha_sym_hp_list = orphanet_df.hp_code.unique()\n",
    "print('Orphanet symptoms (HP): {}'.format(len(orpha_sym_hp_list)))\n",
    "# Number of HPO Curated symptom terms\n",
    "hpo_sym_hp_list = hpo_df.hp_id.unique()\n",
    "print('HPO Curated symptoms (HP): {}'.format(len(hpo_sym_hp_list)))\n",
    "# Number of HPO Text mining symptom terms\n",
    "tg_sym_hp_list = tg_df.hp_id.unique()\n",
    "print('HPO Text mining symptoms (HP): {}'.format(len(tg_sym_hp_list)))\n",
    "# Number of AberOWL symptom terms\n",
    "rh_sym_hp_list = rh_df.hp_id.unique()\n",
    "print('AberOWL symptoms (HP): {}'.format(len(rh_sym_hp_list)))\n",
    "# Coverage\n",
    "ngly1 = set(ngly1_sym_hp_list)\n",
    "hetionet = set(hetionet_sym_hp_list)\n",
    "hsdn = set(hsdn_sym_hp_list)\n",
    "venn3([ngly1,hetionet,hsdn],('NGLY1', 'Hetionet', 'HSDN'))\n",
    "plt.show()\n",
    "# Coverage\n",
    "orphanet = set(orpha_sym_hp_list)\n",
    "venn3([ngly1,hetionet,orphanet],('NGLY1', 'Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "# Coverage\n",
    "hpo = set(hpo_sym_hp_list)\n",
    "venn3([ngly1,hetionet,hpo],('NGLY1', 'Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Coverage\n",
    "hpotm = set(tg_sym_hp_list)\n",
    "venn3([ngly1,hetionet,hpotm],('NGLY1', 'Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "# Coverage\n",
    "aberowl = set(rh_sym_hp_list)\n",
    "venn3([ngly1,hetionet,aberowl],('NGLY1', 'Hetionet', 'AberOWL'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conclusion: All five datasets have NGLY1 symptoms.\n",
    "# Overlap between sources\n",
    "# Curated\n",
    "venn3([ngly1,orphanet,hpo], ('NGLY1', 'Orphanet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Text mined \n",
    "venn3([ngly1,aberowl,hpotm], ('NGLY1', 'AberOWL', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "venn3_unweighted([ngly1,aberowl,hpotm], ('NGLY1', 'AberOWL', 'HPO-TextMining'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data integration: How many NGLY1 symptoms we will recover\n",
    "intersection_hp = (ngly1 & (hsdn | orphanet | hpo | aberowl | hpotm))\n",
    "not_mapped_hp = (ngly1 - intersection_hp)\n",
    "print('Number of NGLY1 symptoms (HP) uncovered with data integration: {}/{}'.format(len(intersection_hp),len(ngly1_sym_hp_list)))\n",
    "print('Number of NGLY1 symptoms (HP) not covered with data integration: {}/{}'.format(len(not_mapped_hp),len(ngly1_sym_hp_list)))\n",
    "print('NGLY1 symptoms (MESH) not covered with data integration:')\n",
    "not_mapped_dict = {'hp_code' : list(not_mapped_hp)}\n",
    "not_mapped_hp_df = pd.DataFrame.from_dict(data=not_mapped_dict)\n",
    "not_mapped_terms_df = pd.merge(not_mapped_hp_df,ngly1_sym_hp_df, on='hp_code')\n",
    "ngly1_hp_not_mapped_terms_df = not_mapped_terms_df\n",
    "not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NLGY symptoms anchor by data integration\n",
    "mapped_dict = {'hp_code' : list(intersection_hp)}\n",
    "mapped_hp_df = pd.DataFrame.from_dict(data=mapped_dict)\n",
    "mapped_terms_df = pd.merge(mapped_hp_df,ngly1_sym_hp_df, on='hp_code')\n",
    "print('NGLY1 symptoms (HP) covered with data integration:')\n",
    "mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check 3 HP sym in hetnet\n",
    "ngly1_hetnet = (ngly1 & hetionet)\n",
    "print('NGLY1 symptoms (HP) in hetnet: {}'.format(ngly1_hetnet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HETNET DISEASES OVERLAPS: hetnet - datasets\n",
    "What dataset covers more hetnet diseases?\n",
    "- AberOWL dataset (136/137)\n",
    "\n",
    "What dataset covers less number?\n",
    "- Orphanet (4/137)\n",
    "\n",
    "Number of hetnet diseases uncovered with data integration: 136/137\n",
    "Number of hetnet diseases not covered with data integration: 1/137\n",
    "Hetnet disease not covered with data integration:\n",
    "\n",
    "doid\tname\tsource\tpathophysiology\n",
    "DOID:9917\tpleural cancer\tDOcancerslim\tneoplastic\n",
    "\n",
    "##### Note: List of hetnet diseases comes from DO nodes integrated in the network; MONDO orphanet2do and DO mesh2do mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mondo orphanet2do mappings\n",
    "mondo_mappings = pd.read_table(\"/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/mondo-orpha2do-mappings.tsv\".format(path))\n",
    "mondo_mappings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load hetnet diseases (DO)\n",
    "# source: Disease nodes from hetionet v1.0 [https://github.com/dhimmel/integrate/blob/master/integrate.ipynb]\n",
    "commit = '75050ea2d4f60e745d3f3578ae03560a2cc0e444'\n",
    "#url = rawgit('dhimmel', 'disease-ontology', commit, 'data/slim-terms.tsv')\n",
    "url = 'https://raw.githubusercontent.com/dhimmel/disease-ontology/' + commit + '/data/slim-terms.tsv'\n",
    "hetionet_dis_do_df = pd.read_table(url)\n",
    "hetionet_dis_do_df.head(2)\n",
    "#len(hetionet_dis_do_df.doid.unique()) # 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hetionet\n",
    "hetionet_dis_do_list = hetionet_dis_do_df.doid.unique()\n",
    "hetionet = set(hetionet_dis_do_list)\n",
    "# hsdn (DO do2mesh mappings)\n",
    "do_mappings = pd.read_table('/home/nuria/workspace/repurposing-hetio/rephetio-dhimmelstein/hetionet+hpo/data-JAN2016/do-do2mesh-mappings.tsv')\n",
    "do_mappings.head(2)\n",
    "hsdn_dis_do_df = hsdn_df.merge(do_mappings, left_on='disease_meshid', right_on='mesh_code')\n",
    "hsdn_dis_do_list = hsdn_dis_do_df.do_code.unique()\n",
    "hsdn = set(hsdn_dis_do_list)\n",
    "# Orphanet (MONDO orphanet2do mappings)\n",
    "orpha_dis_do_df = orphanet_df.merge(mondo_mappings, left_on='orphanet_code', right_on='orphanet')\n",
    "orpha_dis_do_list =orpha_dis_do_df.do.unique()\n",
    "orphanet = set(orpha_dis_do_list)\n",
    "# HPO Curated\n",
    "hpo_dis_do_list = hpo_df.do_id.unique()\n",
    "hpo = set(hpo_dis_do_list)\n",
    "# Groza\n",
    "tg_dis_do_list = tg_df.do_id.unique()\n",
    "hpotm = set(tg_dis_do_list)\n",
    "# Hoehndorf\n",
    "rh_dis_do_list = rh_df.do_id.unique()\n",
    "aberowl = set(rh_dis_do_list)\n",
    "# Counts\n",
    "print('Hetionet diseases (DO): {}'.format(len(hetionet_dis_do_list)))\n",
    "print('HSDN diseases (DO): {}'.format(len(hsdn_dis_do_list)))\n",
    "print('Orphanet diseases (DO): {}'.format(len(orpha_dis_do_list)))\n",
    "print('HPO Curated diseases (DO): {}'.format(len(hpo_dis_do_list)))\n",
    "print('HPO text mining diseases (DO): {}'.format(len(tg_dis_do_list)))\n",
    "print('AberOWL diseases (DO): {}'.format(len(rh_dis_do_list)))\n",
    "# Coverage\n",
    "venn2([hetionet,hsdn],('Hetionet', 'HSDN'))\n",
    "plt.show()\n",
    "venn2([hetionet,orphanet],('Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "venn2([hetionet,hpo],('Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "venn2([hetionet,hpotm],('Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "venn2([hetionet,aberowl],('Hetionet', 'AberOWL'))\n",
    "plt.show()\n",
    "# Overlap between sources\n",
    "# Curated\n",
    "venn3([hetionet,orphanet,hpo], ('Hetionet', 'Orphanet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "# Data mined\n",
    "venn2([hetionet,hsdn], ('Hetionet', 'HSDN'))\n",
    "plt.show()\n",
    "# Text mined \n",
    "venn3([hetionet,aberowl,hpotm], ('Hetionet', 'AberOWL', 'HPO-TextMining'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data integration: How many hetnet diseases we will recover\n",
    "intersection_do = (hetionet & (hsdn | orphanet | hpo | aberowl | hpotm))\n",
    "not_mapped_do = (hetionet - intersection_do)\n",
    "print('Number of hetnet diseases uncovered with data integration: {}/{}'.format(len(intersection_do),len(hetionet_dis_do_list)))\n",
    "print('Number of hetnet diseases not covered with data integration: {}/{}'.format(len(not_mapped_do),len(hetionet_dis_do_list)))\n",
    "print('Hetnet diseases not covered with data integration:')\n",
    "not_mapped_dict = {'doid' : list(not_mapped_do)}\n",
    "not_mapped_do_df = pd.DataFrame.from_dict(data=not_mapped_dict)\n",
    "not_mapped_terms_df = pd.merge(not_mapped_do_df,hetionet_dis_do_df, on='doid')\n",
    "not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGLY1 SYM - HETNET DIS ASSOCIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mappings\n",
    "hpo_umls_mappings = hpo_umls_mappings.loc[:,['hp_code', 'mesh_code']]\n",
    "hpo_umls_mappings.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERLAP DO-MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hetionet diseases\n",
    "hetionet_do_mesh_df = hetionet_df.loc[:,['doid_code', 'mesh_id']]\n",
    "hetionet_do_mesh_df['association'] = hetionet_do_mesh_df.loc[:,['doid_code', 'mesh_id']].apply(lambda x: '-'.join(x), axis=1)\n",
    "len(hetionet_do_mesh_df) # 56658\n",
    "hetionet = set(hetionet_do_mesh_df.association)\n",
    "len(hetionet) # 56658\n",
    "len(hetionet_df[['doid_code']].drop_duplicates()) # DisPhe set: 133 diseases\n",
    "len(hetionet_dis_do_df[['doid']].drop_duplicates()) # Hetionet disease list (DO slim list): 137 diseases\n",
    "hetnet_df = pd.DataFrame(columns=['doid'])\n",
    "hetnet_df['doid'] = hetionet_dis_do_df[['doid']]\n",
    "hetnet_df.rename(columns={'doid' : 'doid_code'}, inplace=True)\n",
    "hetnet_df.head(2) # 137 diseases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly mesh sym not in hetnet\n",
    "ngly1_sym_mesh_total = set(ngly1_sym_mesh_df.mesh_code)\n",
    "ngly1_sym_mesh_InHetnet = (ngly1_sym_mesh_total & set(hetionet_do_mesh_df.mesh_id))\n",
    "ngly1_sym_mesh_notInHetnet = ( ngly1_sym_mesh_total - ngly1_sym_mesh_InHetnet )\n",
    "len(ngly1_sym_mesh_notInHetnet) # 10\n",
    "ndict = {'mesh_code' : list(ngly1_sym_mesh_notInHetnet)}\n",
    "ngly1_df = pd.DataFrame.from_dict(data=ndict)\n",
    "ngly1_df # 10 symptoms (hyperlactatemia (MESH:D065906) node is in hetnet but without sym edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HSDN (0 new ngly1 sym mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# orphanet (4 new ngly1 sym mesh)\n",
    "orpha_ordo2do_hp_df = orphanet_df.merge(mondo_mappings, left_on='orphanet_code', right_on='orphanet')\n",
    "orpha_ordo2do_hp2mesh_df = orpha_ordo2do_hp_df.merge(hpo_umls_mappings, on='hp_code')\n",
    "orpha_df = orpha_ordo2do_hp2mesh_df.loc[:,['do', 'mesh_code']]\n",
    "orpha_df['association'] = orpha_df.loc[:, ['do', 'mesh_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "orpha_df.rename(columns={'do' : 'doid_code'}, inplace=True)\n",
    "orpha_df.head(2) # 7370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "orpha_ngly1_df = orpha_df.merge(ngly1_df, on='mesh_code'); orpha_ngly1_df.shape # 280 ass with ngly1\n",
    "orpha_het_df = orpha_df.merge(hetnet_df, on='doid_code'); orpha_het_df.shape # 75 ass with het diseases\n",
    "orpha_het_ngly1_df = orpha_ngly1_df.merge(hetnet_df, on='doid_code'); orpha_het_ngly1_df.shape # 0 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# no direct hetnet_disease-ngly1_symptom edges in Orphanet\n",
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "orpha_ngly1 = set(orpha_ngly1_df.association)\n",
    "orpha_hetnet = set(orpha_het_df.association)\n",
    "venn2([hetionet,orpha_ngly1], ('Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,orpha_ngly1,orpha_hetnet], ('Hetionet', 'Orphanet-NGLY1-Symptoms', 'Orphanet-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO Curated (4 new ngly1 sym mesh)\n",
    "hpo_df.rename(columns={'do_id' : 'doid_code', 'hp_id' : 'hp_code' }, inplace=True)\n",
    "hpo_hp2mesh_df = hpo_df.merge(hpo_umls_mappings, on='hp_code')\n",
    "# Lost diseases due to mapping:\n",
    "len(hpo_df.doid_code.unique()) # 1317\n",
    "len(hpo_hp2mesh_df.doid_code.unique()) # 1251\n",
    "hpoc_df = hpo_hp2mesh_df.loc[:,['doid_code', 'mesh_code']]\n",
    "hpoc_df['association'] = hpoc_df.loc[:, ['doid_code', 'mesh_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "hpoc_df.head(2) # 14400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "hpo_ngly1_df = hpoc_df.merge(ngly1_df, on='mesh_code'); hpo_ngly1_df.shape # 573 ass with ngly1\n",
    "hpo_het_df = hpoc_df.merge(hetnet_df, on='doid_code'); hpo_het_df.shape # 430 ass with het diseases\n",
    "hpo_het_ngly1_df = hpo_ngly1_df.merge(hetnet_df, on='doid_code'); hpo_het_ngly1_df.shape # 3 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 direct hetnet_disease-ngly1_symptom edges in HPO Curated\n",
    "hpo_het_ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "hpoc_ngly1 = set(hpo_ngly1_df.association)\n",
    "hpoc_hetnet = set(hpo_het_df.association)\n",
    "venn2([hetionet,hpoc_ngly1], ('Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,hpoc_ngly1,hpoc_hetnet], ('Hetionet', 'HPO-Curated-NGLY1-Symptoms', 'HPO-Curated-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO Text mining (5 new ngly1 sym mesh)\n",
    "tg_df.rename(columns={'do_id':'doid_code', 'hp_id':'hp_code'}, inplace=True)\n",
    "hpotg_hp2mesh_df = tg_df.merge(hpo_umls_mappings, on='hp_code')\n",
    "# Lost diseases due to mapping:\n",
    "len(tg_df.doid_code.unique()) # 2086\n",
    "len(hpotg_hp2mesh_df.doid_code.unique()) # 2081\n",
    "hpotg_df = hpotg_hp2mesh_df.loc[:,['doid_code', 'mesh_code']]\n",
    "hpotg_df['association'] = hpotg_df.loc[:, ['doid_code', 'mesh_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "hpotg_df.head(2) # 61563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "hpotg_ngly1_df = hpotg_df.merge(ngly1_df, on='mesh_code'); hpotg_ngly1_df.shape # 413 ass with ngly1\n",
    "hpotg_het_df = hpotg_df.merge(hetnet_df, on='doid_code'); hpotg_het_df.shape # 5908 ass with het diseases\n",
    "hpotg_het_ngly1_df = hpotg_ngly1_df.merge(hetnet_df, on='doid_code'); hpotg_het_ngly1_df.shape # 19 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 19 direct hetnet_disease-ngly1_symptom edges in HPO Text mining\n",
    "hpotg_het_ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "hpotg_ngly1 = set(hpotg_ngly1_df.association)\n",
    "hpotg_hetnet = set(hpotg_het_df.association)\n",
    "venn2([hetionet,hpotg_ngly1], ('Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,hpotg_ngly1,hpotg_hetnet], ('Hetionet', 'HPO-TextMining-NGLY1-Symptoms', 'HPO-TextMining-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AberOWL Text mining (5 new ngly1 sym mesh)\n",
    "rh_df.rename(columns={'do_id':'doid_code', 'hp_id':'hp_code'}, inplace=True)\n",
    "rh_hp2mesh_df = rh_df.merge(hpo_umls_mappings, on='hp_code')\n",
    "# Lost diseases due to mapping:\n",
    "len(rh_df.doid_code.unique()) # 6100\n",
    "len(rh_hp2mesh_df.doid_code.unique()) # 6005\n",
    "rhtm_df = rh_hp2mesh_df.loc[:,['doid_code', 'mesh_code']]\n",
    "rhtm_df['association'] = rhtm_df.loc[:, ['doid_code', 'mesh_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "rhtm_df.head(2) # 30187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "rh_ngly1_df = rhtm_df.merge(ngly1_df, on='mesh_code'); rh_ngly1_df.shape # 145 ass with ngly1\n",
    "rh_het_df = rhtm_df.merge(hetnet_df, on='doid_code'); rh_het_df.shape # 707 ass with het diseases\n",
    "rh_het_ngly1_df = rh_ngly1_df.merge(hetnet_df, on='doid_code'); rh_het_ngly1_df.shape # 1 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 direct hetnet_disease-ngly1_symptom edges in AberOWL\n",
    "rh_het_ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "rh_ngly1 = set(rh_ngly1_df.association)\n",
    "rh_hetnet = set(rh_het_df.association)\n",
    "venn2([hetionet,rh_ngly1], ('Hetionet', 'AberOWL'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,rh_ngly1,rh_hetnet], ('Hetionet', 'AberOWL-NGLY1-Symptoms', 'AberOWL-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overlap ngly1_Sym-Disease edges\n",
    "venn3([hpoc_ngly1,hpotg_ngly1,rh_ngly1], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "# overlap ngly1_Sym-Hetnet_Disease edges\n",
    "hpoc = set(hpo_het_ngly1_df.association)\n",
    "hpotg = set(hpotg_het_ngly1_df.association)\n",
    "aber = set(rh_het_ngly1_df.association)\n",
    "venn3([hpoc,hpotg,aber], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "# overlap ngly1 sym nodes with edge to hetnet found in external sources\n",
    "hpoc = set(hpo_het_ngly1_df.mesh_code)\n",
    "hpotg = set(hpotg_het_ngly1_df.mesh_code)\n",
    "aber = set(rh_het_ngly1_df.mesh_code)\n",
    "venn3_unweighted([hpoc,hpotg,aber], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "print('ngly1-hetnet dis-sym in HPO curated: {}'.format(hpoc))\n",
    "print('ngly1-hetnet dis-sym in HPO Text mining: {}'.format(hpotg))\n",
    "print('ngly1-hetnet dis-sym in AberOWL: {}'.format(aber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms described in MESH (15)\n",
    "ngly1_sym_mesh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms not in hetnet (10)\n",
    "ngly1_df = ngly1_df.merge(ngly1_sym_mesh_df, how='left', on='mesh_code')\n",
    "ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms not in hetnet and not in external datasets -> text mining (3)\n",
    "ngly1_not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of ngly1 sym (mesh) that we can anchor to hetnet (7/10 ngly1 not in hetnet found in external sources) (3)\n",
    "ngly1_anchor_edge = set(hpoc | hpotg | aber)\n",
    "data = {'mesh_code':list(ngly1_anchor_edge)}\n",
    "ngly1_anchor_edge_df = pd.DataFrame.from_dict(data)\n",
    "ngly1_anchor_edge_df = ngly1_anchor_edge_df.merge(ngly1_sym_mesh_df, how='left', on='mesh_code')\n",
    "ngly1_anchor_edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 sym without a link to a hetnet disease but with link to other diseases in the datasets\n",
    "len(set(orpha_ngly1_df.mesh_code)) # 5\n",
    "orpha_ngly1_do_set = (set(orpha_ngly1_df.mesh_code) - set(orpha_het_ngly1_df.mesh_code))\n",
    "orpha_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(hpo_ngly1_df.mesh_code)) # 6\n",
    "hpo_ngly1_do_set = (set(hpo_ngly1_df.mesh_code) - set(hpo_het_ngly1_df.mesh_code))\n",
    "hpo_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(hpotg_ngly1_df.mesh_code)) # 6\n",
    "hpotg_ngly1_do_set = (set(hpotg_ngly1_df.mesh_code) - set(hpotg_het_ngly1_df.mesh_code))\n",
    "hpotg_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(rh_ngly1_df.mesh_code)) # 7\n",
    "rh_ngly1_do_set = (set(rh_ngly1_df.mesh_code) - set(rh_het_ngly1_df.mesh_code))\n",
    "rh_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ngly1_set = (set(orpha_ngly1_df.mesh_code) | set(hpo_ngly1_df.mesh_code) | set(hpotg_ngly1_df.mesh_code) | set(rh_ngly1_df.mesh_code))\n",
    "all_ngly1_het_set = (set(orpha_het_ngly1_df.mesh_code) | set(hpo_het_ngly1_df.mesh_code) | set(hpotg_het_ngly1_df.mesh_code) | set(rh_het_ngly1_df.mesh_code))\n",
    "all_ngly1_do_set = set(all_ngly1_set - all_ngly1_het_set)\n",
    "len(all_ngly1_do_set) # 7\n",
    "data = {'mesh_code': list(all_ngly1_do_set)}\n",
    "all_ngly1_do_df = pd.DataFrame.from_dict(data)\n",
    "all_ngly1_do_df = all_ngly1_do_df.merge(ngly1_sym_mesh_df, how='left', on='mesh_code')\n",
    "all_ngly1_do_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check mesh\n",
    "all = [orpha_het_ngly1_df, hpo_het_ngly1_df, hpotg_het_ngly1_df, rh_het_ngly1_df]\n",
    "all_df = pd.concat(all)\n",
    "all_df.mesh_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVERLAP DO-HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hetionet\n",
    "# mapping sym mesh to hp\n",
    "hetionet_do_hp_df = hetionet_do_mesh_df.merge(hpo_umls_mappings, left_on='mesh_id', right_on='mesh_code')\n",
    "hetionet_do_hp_df['association'] = hetionet_do_hp_df.loc[:,['doid_code', 'hp_code']].apply(lambda x: '-'.join(x), axis=1)\n",
    "len(hetionet_do_hp_df) # 22211\n",
    "hetionet = set(hetionet_do_hp_df.association)\n",
    "len(hetionet) # 22211\n",
    "len(hetionet_df[['doid_code']].drop_duplicates()) # DisPhe set: 133 diseases\n",
    "len(hetionet_dis_do_df[['doid']].drop_duplicates()) # Hetionet disease list (DO slim list): 137 diseases\n",
    "hetnet_df = pd.DataFrame(columns=['doid'])\n",
    "hetnet_df['doid'] = hetionet_dis_do_df[['doid']]\n",
    "hetnet_df.rename(columns={'doid' : 'doid_code'}, inplace=True)\n",
    "hetnet_df.head(2) # 137 diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly hp sym not in hetnet\n",
    "ngly1_sym_hp_total = set(ngly1_sym_hp_df.hp_code)\n",
    "ngly1_sym_hp_InHetnet = (ngly1_sym_hp_total & set(hetionet_do_hp_df.hp_code))\n",
    "ngly1_sym_hp_notInHetnet = ( ngly1_sym_hp_total - ngly1_sym_hp_InHetnet )\n",
    "len(ngly1_sym_hp_notInHetnet) # 25\n",
    "ndict = {'hp_code' : list(ngly1_sym_hp_notInHetnet)}\n",
    "ngly1_df = pd.DataFrame.from_dict(data=ndict)\n",
    "ngly1_df.head(2) # 25 symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HSDN (0 new ngly1 sym mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# orphanet (5 new ngly1 sym mesh)\n",
    "orpha_ordo2do_hp_df = orphanet_df.merge(mondo_mappings, left_on='orphanet_code', right_on='orphanet')\n",
    "orpha_df = orpha_ordo2do_hp_df.loc[:,['do', 'hp_code']]\n",
    "orpha_df['association'] = orpha_df.loc[:, ['do', 'hp_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "orpha_df.rename(columns={'do' : 'doid_code'}, inplace=True)\n",
    "orpha_df.head(2) # 16161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "orpha_ngly1_df = orpha_df.merge(ngly1_df, on='hp_code'); orpha_ngly1_df.shape # 511 ass with ngly1\n",
    "orpha_het_df = orpha_df.merge(hetnet_df, on='doid_code'); orpha_het_df.shape # 115 ass with het diseases\n",
    "orpha_het_ngly1_df = orpha_ngly1_df.merge(hetnet_df, on='doid_code'); orpha_het_ngly1_df.shape # 1 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 direct hetnet_disease-ngly1_symptom edges in Orphanet\n",
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "orpha_ngly1 = set(orpha_ngly1_df.association)\n",
    "orpha_hetnet = set(orpha_het_df.association)\n",
    "venn2([hetionet,orpha_ngly1], ('Hetionet', 'Orphanet'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,orpha_ngly1,orpha_hetnet], ('Hetionet', 'Orphanet-NGLY1-Symptoms', 'Orphanet-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO Curated (6 new ngly1 sym mesh)\n",
    "hpoc_df = hpo_df\n",
    "hpoc_df['association'] = hpoc_df.loc[:, ['doid_code', 'hp_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "hpoc_df.head(2) # 38913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "hpo_ngly1_df = hpoc_df.merge(ngly1_df, on='hp_code'); hpo_ngly1_df.shape # 1636 ass with ngly1\n",
    "hpo_het_df = hpoc_df.merge(hetnet_df, on='doid_code'); hpo_het_df.shape # 889 ass with het diseases\n",
    "hpo_het_ngly1_df = hpo_ngly1_df.merge(hetnet_df, on='doid_code'); hpo_het_ngly1_df.shape # 18 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 18 direct hetnet_disease-ngly1_symptom edges in HPO Curated\n",
    "hpo_het_ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "hpoc_ngly1 = set(hpo_ngly1_df.association)\n",
    "hpoc_hetnet = set(hpo_het_df.association)\n",
    "venn2([hetionet,hpoc_ngly1], ('Hetionet', 'HPO-Curated'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,hpoc_ngly1,hpoc_hetnet], ('Hetionet', 'HPO-Curated-NGLY1-Symptoms', 'HPO-Curated-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HPO Text mining (6 new ngly1 sym mesh)\n",
    "hpotg_df = tg_df\n",
    "hpotg_df['association'] = hpotg_df.loc[:, ['doid_code', 'hp_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "hpotg_df.head(2) # 95045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "hpotg_ngly1_df = hpotg_df.merge(ngly1_df, on='hp_code'); hpotg_ngly1_df.shape # 1094 ass with ngly1\n",
    "hpotg_het_df = hpotg_df.merge(hetnet_df, on='doid_code'); hpotg_het_df.shape # 8507 ass with het diseases\n",
    "hpotg_het_ngly1_df = hpotg_ngly1_df.merge(hetnet_df, on='doid_code'); hpotg_het_ngly1_df.shape # 79 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 79 direct hetnet_disease-ngly1_symptom edges in HPO Curated\n",
    "hpotg_het_ngly1_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "hpotg_ngly1 = set(hpotg_ngly1_df.association)\n",
    "hpotg_hetnet = set(hpotg_het_df.association)\n",
    "venn2([hetionet,hpotg_ngly1], ('Hetionet', 'HPO-TextMining'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,hpotg_ngly1,hpotg_hetnet], ('Hetionet', 'HPO-TextMining-NGLY1-Symptoms', 'HPO-TextMining-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AberOWL Text mining (7 new ngly1 sym mesh)\n",
    "rhtm_df = rh_df\n",
    "rhtm_df['association'] = rhtm_df.loc[:, ['doid_code', 'hp_code']].apply(lambda x: '-'.join(x), axis =1)\n",
    "rhtm_df.head(2) # 84508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subsetting the associations with a ngly1 sym and a hetnet disease\n",
    "rh_ngly1_df = rhtm_df.merge(ngly1_df, on='hp_code'); rh_ngly1_df.shape # 541 ass with ngly1\n",
    "rh_het_df = rhtm_df.merge(hetnet_df, on='doid_code'); rh_het_df.shape # 1934 ass with het diseases\n",
    "rh_het_ngly1_df = rh_ngly1_df.merge(hetnet_df, on='doid_code'); rh_het_ngly1_df.shape # 1 ass ngly1 - het diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 6 direct hetnet_disease-ngly1_symptom edges in HPO Curated\n",
    "rh_het_ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 symptoms not in hetionet that have disease annotation in an external source\n",
    "rh_ngly1 = set(rh_ngly1_df.association)\n",
    "rh_hetnet = set(rh_het_df.association)\n",
    "venn2([hetionet,rh_ngly1], ('Hetionet', 'AberOWL'))\n",
    "plt.show()\n",
    "venn3_unweighted([hetionet,rh_ngly1,rh_hetnet], ('Hetionet', 'AberOWL-NGLY1-Symptoms', 'AberOWL-Hetnet-Diseases'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overlap ngly1_Sym-Disease edges\n",
    "venn3([hpoc_ngly1,hpotg_ngly1,rh_ngly1], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "# overlap ngly1_Sym-Hetnet_Disease edges\n",
    "hpoc = set(hpo_het_ngly1_df.association)\n",
    "hpotg = set(hpotg_het_ngly1_df.association)\n",
    "aber = set(rh_het_ngly1_df.association)\n",
    "venn3([hpoc,hpotg,aber], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "# overlap ngly1 sym nodes with edge to hetnet found in external sources\n",
    "hpoc = set(hpo_het_ngly1_df.hp_code)\n",
    "hpotg = set(hpotg_het_ngly1_df.hp_code)\n",
    "aber = set(rh_het_ngly1_df.hp_code)\n",
    "venn3_unweighted([hpoc,hpotg,aber], ('HPO-Curated', 'HPO-TextMining', 'AberOWL'))\n",
    "plt.show()\n",
    "print('ngly1-hetnet dis-sym in HPO curated: {}'.format(hpoc))\n",
    "print('ngly1-hetnet dis-sym in HPO Text mining: {}'.format(hpotg))\n",
    "print('ngly1-hetnet dis-sym in AberOWL: {}'.format(aber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms described in HP (28)\n",
    "ngly1_sym_hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms not in hetnet (25)\n",
    "ngly1_df = ngly1_df.merge(ngly1_sym_hp_df, how='left', on='hp_code')\n",
    "ngly1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total NGLY1 symptoms not in hetnet and not in external datasets -> text mining (1)\n",
    "ngly1_hp_not_mapped_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of ngly1 sym (hp) that we can anchor to hetnet (24/25 ngly1 not in hetnet found in external sources) (15)\n",
    "ngly1_anchor_edge = set(hpoc | hpotg | aber)\n",
    "data = {'hp_code':list(ngly1_anchor_edge)}\n",
    "ngly1_anchor_edge_df = pd.DataFrame.from_dict(data)\n",
    "ngly1_anchor_edge_df = ngly1_anchor_edge_df.merge(ngly1_sym_hp_df, how='left', on='hp_code')\n",
    "ngly1_anchor_edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ngly1 sym without a link to a hetnet disease but with link to other diseases in the datasets\n",
    "len(set(orpha_ngly1_df.hp_code)) # 5\n",
    "orpha_ngly1_do_set = (set(orpha_ngly1_df.hp_code) - set(orpha_het_ngly1_df.hp_code))\n",
    "orpha_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(hpo_ngly1_df.hp_code)) # 6\n",
    "hpo_ngly1_do_set = (set(hpo_ngly1_df.hp_code) - set(hpo_het_ngly1_df.hp_code))\n",
    "hpo_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(hpotg_ngly1_df.hp_code)) # 6\n",
    "hpotg_ngly1_do_set = (set(hpotg_ngly1_df.hp_code) - set(hpotg_het_ngly1_df.hp_code))\n",
    "hpotg_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(rh_ngly1_df.hp_code)) # 7\n",
    "rh_ngly1_do_set = (set(rh_ngly1_df.hp_code) - set(rh_het_ngly1_df.hp_code))\n",
    "rh_ngly1_do_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ngly1_set = (set(orpha_ngly1_df.hp_code) | set(hpo_ngly1_df.hp_code) | set(hpotg_ngly1_df.hp_code) | set(rh_ngly1_df.hp_code))\n",
    "all_ngly1_het_set = (set(orpha_het_ngly1_df.hp_code) | set(hpo_het_ngly1_df.hp_code) | set(hpotg_het_ngly1_df.hp_code) | set(rh_het_ngly1_df.hp_code))\n",
    "all_ngly1_do_set = set(all_ngly1_set - all_ngly1_het_set)\n",
    "len(all_ngly1_do_set) # 7\n",
    "data = {'hp_code': list(all_ngly1_do_set)}\n",
    "all_ngly1_do_df = pd.DataFrame.from_dict(data)\n",
    "all_ngly1_do_df = all_ngly1_do_df.merge(ngly1_sym_hp_df, how='left', on='hp_code')\n",
    "all_ngly1_do_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check hpo\n",
    "all = [orpha_het_ngly1_df, hpo_het_ngly1_df, hpotg_het_ngly1_df, rh_het_ngly1_df]\n",
    "all_df = pd.concat(all)\n",
    "all_df.hp_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# which NGLY1 symptoms anchor to hetionet with MESH? with HPO? 3/10 (MESH) and 15/25 (HPO) \n",
    "# Are there still some NGLY1 symptoms without a hetionet disease link that we could uncover adding Monarch? \n",
    "# or with (data/text)mining?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
